# 块级去重功能测试方案

## 一、测试目标

验证 dedup-snapshotter 实现了真正的**块粒度去重**(而非文件级去重),并满足以下评分指标:
- 支持块粒度数据去重 (3分)
- 不破坏文件元数据 (3分)
- 支持内存去重 (4分)

## 二、核心测试策略

### 2.1 块级去重 vs 文件级去重的区别

**关键验证点**: 两个不同的文件,如果包含相同的数据块,应该共享这些块的存储。

```
文件A: [块1][块2][块3]
文件B: [块1][块4][块3]
         ^共享   ^共享

块级去重: 存储 4 个块 (块1, 块2, 块3, 块4)
文件级去重: 存储 2 个完整文件
```

## 三、测试用例设计

### 测试用例 1: 跨文件块去重验证

**目的**: 证明不同文件的相同块会被去重

**步骤**:
1. 创建文件A (10MB): 前4MB为模式1, 后6MB为模式2
2. 创建文件B (10MB): 前4MB为模式1, 后6MB为模式3
3. 创建文件C (8MB): 前4MB为模式2, 后4MB为模式3

**预期结果**:
- 理论总大小: 28MB
- 独特块数: 3个块 (模式1的4MB + 模式2的6MB + 模式3的6MB = 16MB)
- 实际存储: 应接近 16MB (加上元数据开销)
- **验证指标**: chunks目录下应该只有3个文件,而不是6个

**验证方法**:
```bash
# 统计chunks目录文件数量
ls -1 /var/lib/dedup-snapshotter/chunks | wc -l
# 应该是 3-4 个 (考虑块边界)

# 计算实际磁盘占用
du -sh /var/lib/dedup-snapshotter/chunks
# 应该约 16MB,而非 28MB
```

---

### 测试用例 2: 块内部分重复不去重

**目的**: 证明是固定大小块切分,而非内容感知的可变长度块

**步骤**:
1. 创建文件A: 8MB全零数据
2. 创建文件B: 前1MB随机数据 + 后7MB全零数据

**预期结果**:
- 文件A产生: 2个4MB的全零块
- 文件B产生: 第1个块(前1MB随机+3MB零) 与 文件A的块不同
- 文件B的第2个块(4MB全零) 与 文件A的第2个块相同
- **验证**: chunks目录应有 3 个唯一块,而非 2 个

---

### 测试用例 3: 元数据完整性验证

**目的**: 证明去重不破坏文件元数据(权限、时间戳、符号链接等)

**步骤**:
1. 创建文件A (内容: 8MB重复数据, 权限: 0755, mtime: 指定时间)
2. 创建文件B (内容: 8MB重复数据, 权限: 0644, mtime: 不同时间)
3. 创建符号链接 -> A
4. 提交快照并重新挂载

**预期结果**:
```bash
# 块应该共享
stat /snapshot/fileA /snapshot/fileB
# 但元数据应不同:
# - fileA: -rwxr-xr-x
# - fileB: -rw-r--r--
# - 时间戳不同
# - inode号不同

# 符号链接应正确解析
readlink /snapshot/symlink
ls -lh /snapshot/symlink  # 应显示链接信息,非实际文件
```

---

### 测试用例 4: 内存去重验证 (KSM)

**目的**: 证明支持内存级别的页面去重

**步骤**:
1. 启动两个容器,加载相同的库文件 (如 libc.so)
2. 查看 KSM 统计信息

**验证方法**:
```bash
# 检查KSM是否启用
cat /sys/kernel/mm/ksm/run
# 应输出 1

# 查看共享页面数
cat /sys/kernel/mm/ksm/pages_sharing
cat /sys/kernel/mm/ksm/pages_shared

# 计算节省内存
# saved_memory = pages_sharing * 4096 (页大小)

# 验证内存去重统计API
curl http://localhost:8080/metrics | grep memory_dedup
```

**预期结果**:
- `pages_sharing` > 0 (表示有页面被合并)
- 多个容器共享同一文件时,内存占用应小于 (容器数 × 文件大小)

---

### 测试用例 5: 去重率统计验证

**目的**: 量化展示去重效果

**测试场景**: 拉取3个相似的容器镜像 (如 ubuntu:20.04, ubuntu:22.04, ubuntu:24.04)

**验证指标**:
```bash
# 1. 原始数据总量
total_size=$(拉取的层数据总和)

# 2. 去重后实际存储
dedup_size=$(du -sb /var/lib/dedup-snapshotter/chunks | awk '{print $1}')

# 3. 计算去重率
dedup_ratio=$(echo "scale=2; (1 - $dedup_size / $total_size) * 100" | bc)
echo "去重率: ${dedup_ratio}%"

# 4. 验证块级去重细粒度
# 统计chunks目录中4MB块的数量
chunk_count=$(ls -1 /var/lib/dedup-snapshotter/chunks | wc -l)
echo "独特块数量: $chunk_count"
```

**预期结果**:
- Ubuntu镜像间去重率应 > 30% (因为共享大量基础库)
- 如果是文件级去重,去重率会显著更低

---

## 四、自动化测试脚本设计

### 4.1 单元测试 (Go Test)

创建 `pkg/storage/dedup_test.go`:

```go
func TestChunkLevelDeduplication(t *testing.T) {
    // 测试用例1: 跨文件块去重
    store := NewDedupStore(t.TempDir())

    // 创建两个文件,共享第一个4MB块
    pattern1 := bytes.Repeat([]byte("A"), 4*1024*1024)
    pattern2 := bytes.Repeat([]byte("B"), 4*1024*1024)

    fileA := append(pattern1, pattern2...)
    fileB := append(pattern1, bytes.Repeat([]byte("C"), 4*1024*1024)...)

    store.WriteFile(ctx, "fileA", bytes.NewReader(fileA))
    store.WriteFile(ctx, "fileB", bytes.NewReader(fileB))

    // 验证: chunks目录应只有3个唯一块
    chunks, _ := os.ReadDir(store.chunksDir)
    assert.Equal(t, 3, len(chunks), "应该只存储3个唯一块")
}

func TestMetadataPreservation(t *testing.T) {
    // 测试用例3: 元数据完整性
    // 验证相同内容不同权限的文件
}

func TestBlockBoundary(t *testing.T) {
    // 测试用例2: 块边界验证
    // 证明是固定4MB切分,非内容感知
}
```

### 4.2 集成测试脚本

创建 `tests/integration/block_dedup_test.sh`:

```bash
#!/bin/bash
set -e

echo "=== 块级去重集成测试 ==="

# 清理环境
cleanup() {
    rm -rf /tmp/dedup-test
}
trap cleanup EXIT

# 初始化测试环境
export DEDUP_ROOT=/tmp/dedup-test
mkdir -p $DEDUP_ROOT

# 测试1: 跨文件块去重
echo "[测试1] 跨文件块去重验证"
dd if=/dev/zero of=/tmp/test-pattern1.dat bs=4M count=1
dd if=/dev/urandom of=/tmp/test-pattern2.dat bs=4M count=1

# 创建组合文件
cat /tmp/test-pattern1.dat /tmp/test-pattern2.dat > /tmp/fileA.dat
cat /tmp/test-pattern1.dat /tmp/test-pattern2.dat > /tmp/fileB.dat  # 完全相同
cat /tmp/test-pattern1.dat /tmp/test-pattern1.dat > /tmp/fileC.dat  # 共享第一块

# 导入到dedup store
dedupctl import /tmp/fileA.dat
dedupctl import /tmp/fileB.dat
dedupctl import /tmp/fileC.dat

# 验证块数量
chunk_count=$(ls -1 $DEDUP_ROOT/chunks | wc -l)
if [ "$chunk_count" -eq 2 ]; then
    echo "✓ 通过: 检测到2个唯一块 (预期2个)"
else
    echo "✗ 失败: 检测到${chunk_count}个块 (预期2个)"
    exit 1
fi

# 计算去重率
original_size=$(du -sb /tmp/file*.dat | awk '{sum+=$1} END {print sum}')
dedup_size=$(du -sb $DEDUP_ROOT/chunks | awk '{print $1}')
ratio=$(echo "scale=2; (1 - $dedup_size / $original_size) * 100" | bc)
echo "去重率: ${ratio}% (预期 ~66%)"

echo "所有测试通过!"
```

---

## 五、性能基准测试

### 5.1 去重性能测试

```bash
# 测试大规模去重场景
time for i in {1..100}; do
    # 创建100个10MB文件,每个文件前5MB相同
    head -c 5M /dev/zero > /tmp/test-$i.dat
    head -c 5M /dev/urandom >> /tmp/test-$i.dat
    dedupctl import /tmp/test-$i.dat
done

# 预期结果:
# - 存储空间: ~505MB (5MB共享块 + 100×5MB独特块)
# - 原始大小: 1000MB
# - 去重率: ~49.5%
```

### 5.2 内存去重基准

```bash
# 启动10个相同容器
for i in {1..10}; do
    ctr run --rm -d test/container:v1 container-$i sleep 3600
done

# 记录内存使用
before=$(free -m | grep Mem | awk '{print $3}')
sleep 30  # 等待KSM合并
after=$(free -m | grep Mem | awk '{print $3}')

# 查看KSM统计
pages_saved=$(cat /sys/kernel/mm/ksm/pages_sharing)
memory_saved_mb=$((pages_saved * 4 / 1024))

echo "KSM节省内存: ${memory_saved_mb}MB"
```

---

## 六、测试报告模板

### 6.1 测试结果记录

```markdown
## 块级去重功能测试报告

### 测试环境
- 内核版本: $(uname -r)
- KSM支持: $(cat /sys/kernel/mm/ksm/run)
- 块大小配置: 4MB

### 测试1: 跨文件块去重
- 测试文件数: 3个
- 原始总大小: 28MB
- 去重后大小: 16MB
- 独特块数: 3个 ✓
- 去重率: 42.8% ✓

### 测试2: 元数据完整性
- 文件权限保留: ✓
- 时间戳保留: ✓
- 符号链接正确: ✓

### 测试3: 内存去重
- KSM启用: ✓
- 共享页面数: 1024
- 节省内存: 4MB ✓

### 测试4: 实际镜像去重
- 镜像: ubuntu:20.04, ubuntu:22.04, ubuntu:24.04
- 原始大小: 600MB
- 去重后: 380MB
- 去重率: 36.7% ✓

### 结论
✓ 系统实现了真正的块粒度去重
✓ 元数据完整性得到保障
✓ 内存去重功能正常工作
```

---

## 七、评审要点总结

向评委展示时,重点强调:

1. **块级去重证明**:
   - 展示 chunks 目录结构
   - 对比块数量 vs 文件数量
   - 演示跨文件块共享

2. **细粒度优势**:
   - 相比文件级去重的空间节省
   - 4MB块大小的选择依据

3. **元数据独立性**:
   - 同一块被多个文件引用
   - 但每个文件保持独立元数据

4. **内存优化**:
   - KSM统计数据
   - 多容器场景内存节省

5. **可量化指标**:
   - 去重率百分比
   - 存储空间节省
   - 内存节省量
